{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom efficientnet_pytorch import EfficientNet\n\nimport os\nimport sys\nimport time\nimport random\nfrom tqdm.auto import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Settings"},{"metadata":{},"cell_type":"markdown","source":"## Path Settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DATA = '/kaggle/input/fashiondata/image_train_Kaggle.csv'\nTEST_DATA = '/kaggle/input/fashiondata/image_test_Kaggle.csv'\nSAVE_DIR = '/kaggle/working/saved_ckpt'\n\nif not os.path.exists(SAVE_DIR):\n    os.mkdir(SAVE_DIR)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"SEED = 0\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBATCH_SIZE = 128\nNUM_WORKERS = 4\nPIN_MEMORY = True\n\n# Learning rate scheduling\nlr_s = True\nlr_w = True\n\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    print('Set seed', seed)\n    \nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_DATA)\ndf_test = pd.read_csv(TEST_DATA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of training data items: {len(df_train)}')\nprint(f'Number of test data items: {len(df_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_random_grid(df, n, m):\n    \"\"\"Plot an nxm grid of random images from the training dataframe\"\"\"\n    \n    idxs = np.random.choice(len(df), n*m, replace=False)\n    images = df.iloc[idxs, 1:].values.reshape(-1, 28, 28)\n    labels = df.iloc[idxs, 0].values.astype(str)\n    \n    fig, ax = plt.subplots(n, m, figsize=(5,5))\n    for i in range(n):\n        for j in range(m):\n            ax[i, j].imshow(images[i*j + j], cmap='gray')\n            ax[i, j].axis('off')\n            ax[i, j].set_title(labels[i*j + j])\n            \nplot_random_grid(df_train, 3, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distrib(df):\n    labels = df.iloc[:, 0].values.ravel()\n    freq = np.bincount(labels)\n    print('Class distribution:', freq)\n    plt.bar(np.arange(10), freq)\n    \nplot_distrib(df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_idx = np.arange(len(df_train))\nval_idx = np.random.choice(train_idx, int(len(df_train) * 0.2), replace=False)\ntrain_idx = train_idx[np.logical_not(np.isin(train_idx, val_idx))]\ndf_train_ = df_train.iloc[train_idx]\ndf_val_ = df_train.iloc[val_idx]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Wrapper"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FashionDataset(Dataset):\n    \"\"\"Dataset wrapper\"\"\"\n    def __init__(self, df, transforms=None, train=True):\n        self.df = df\n        self.transforms = transforms\n        self.train = train\n        \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, index):\n        row = self.df.iloc[index].values.ravel()\n        if self.train:\n            label, image = row[0], row[1:]\n        else:\n            id, image = row[0], row[1:]\n            \n        image = Image.fromarray(\n            image.reshape(28, 28).astype(np.uint8)\n        ).convert('RGB')\n        \n        if self.transforms is not None:\n            image = self.transforms(image)\n        \n        return (image, label) if self.train else (image, id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_mean_std(df):\n    images = df.iloc[:, 1:].values/255\n    return images.mean(), np.std(images)\n\ntrain_mean, train_std = calculate_mean_std(df_train_)\nval_mean, val_std = calculate_mean_std(df_val_)\ntest_mean, test_std = calculate_mean_std(df_test)\nprint(train_mean, train_std)\nprint(val_mean, val_std)\nprint(test_mean, test_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose(\n    [   \n        transforms.RandomRotation(10),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(train_mean, train_std)\n    ]\n)\n\nval_transforms = transforms.Compose(\n    [\n        transforms.ToTensor(),\n        transforms.Normalize(val_mean, test_std)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = FashionDataset(df_train_, transforms=train_transforms, \\\n                            train=True)\ntrainloader = DataLoader(data_train, batch_size=BATCH_SIZE, \\\n                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, \\\n                         shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_val = FashionDataset(df_val_, transforms=val_transforms, \\\n                           train=True)\nvalloader = DataLoader(data_val, batch_size=BATCH_SIZE, \\\n                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, \\\n                         shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_params(net):\n    return sum(map(lambda p: p.numel(), net.parameters()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = EfficientNet.from_pretrained('efficientnet-b0')\nnet._fc = nn.Linear(1280, 10, bias=True)\nprint('Params: {:.2f}M'.format(count_params(net)/1e6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_ckpt(epoch):\n    save_path = os.path.join(SAVE_DIR, f'best.pth')\n    best_ckpt = {\n        'epoch': epoch,\n        'model_state_dict': net.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict()\n    }\n    torch.save(best_ckpt, save_path)\n    print('Saved current best at', save_path)\n    \ndef load_ckpt():\n    load_path = os.path.join(SAVE_DIR, f'best.pth')\n    ckpt = torch.load(load_path)\n    net.load_state_dict(ckpt['model_state_dict'])\n    optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n    print('Restored best val ckpt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(start_epoch, end_epoch):\n    best_acc = 0\n    best_ckpt = None\n    \n    net.train()\n    for epoch in range(start_epoch, end_epoch+1):\n        t0 = time.time()\n        running_loss = 0.0\n        \n        # Train\n        for images, labels in tqdm(trainloader):\n            \n            if epoch <= w and lr_w:\n                warmup_scheduler.step()\n                \n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            \n            optimizer.zero_grad()\n            preds = net(images)\n            loss = criterion(preds, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        # Validation\n        if not epoch % eval_freq:\n            val_acc, val_loss = evaluate(valloader)\n            if val_acc > best_acc:\n                best_acc = val_acc\n                save_ckpt(epoch)\n            else:\n                load_ckpt()\n                \n                \n        # Scheduling\n        if epoch > w and lr_s:\n            train_scheduler.step()\n            \n        logs = [\n            f'Epoch: {epoch}/{end_epoch}',\n            f'loss: {running_loss}',\n            f'LR: {optimizer.param_groups[0][\"lr\"]}',\n            f'Time: {time.time()-t0}s'\n        ]\n        \n        print(' | '.join(logs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(dataloader):\n    net.eval()\n    test_loss = 0.0\n    correct = 0.0\n\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader):\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            preds = net(images)\n            loss = criterion(preds, labels)\n            test_loss += loss.item()\n            _, preds = preds.max(1)\n            \n            correct += preds.eq(labels).sum()\n    \n    net.train()\n    \n    accuracy = correct / len(dataloader.dataset)\n    print('Accuracy:', accuracy, 'Test loss:', test_loss)\n    return accuracy, test_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WarmUpLR(lr_scheduler._LRScheduler):\n    \"\"\"Warmup learning rate scheduler\"\"\"\n    def __init__(self, optimizer, total_iters, last_epoch=-1):\n        self.total_iters = total_iters\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LabelSmoothedCrossEntropy(preds, labels, epsilon=0.1, num_classes=10):\n    \"\"\"Cross Entropy with Label Smoothing\"\"\"\n    one_hot = torch.zeros_like(preds).scatter(1, labels.view(-1, 1), 1)\n    one_hot = one_hot*(1-epsilon) + (1-one_hot)*epsilon/(num_classes-1)\n    log_prb = F.log_softmax(preds, dim=1)\n    loss = -(one_hot * log_prb).sum(dim=1)\n    return loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = net.to(DEVICE)\noptimizer = optim.SGD(net.parameters(), lr=0.001, \\\n                      momentum=0.9, weight_decay=5e-4)\ncriterion = LabelSmoothedCrossEntropy\neval_freq = 5 # Validation after how many epochs\n\n# Scheduling \nw = 4 # how many warmups\nif lr_w:\n    warmup_scheduler = WarmUpLR(optimizer, len(trainloader) * w)\n    print('Warmup scheduler initialized')\n\nif lr_s:\n    train_scheduler = lr_scheduler.MultiStepLR(\n        optimizer,\n        milestones=[60,100,140,160,180],\n        gamma=0.2\n    )\n    print('Train scheduler initialized')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(1, 200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Test Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_preds(dataloader):\n    net.eval()\n    data_out = []\n    with torch.no_grad():\n        for images, id in tqdm(dataloader):\n            images = images.to(DEVICE)\n            preds = net(images)\n            _, preds = preds.max(1)\n            id = id.numpy().ravel()\n            preds = preds.cpu().numpy().ravel()\n            batch_preds = np.vstack([id, preds]).T.tolist()\n            data_out += batch_preds\n    return data_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transforms = transforms.Compose(\n    [   \n        transforms.ToTensor(),\n        transforms.Normalize(test_mean, test_std)\n    ]\n)\n\ndata_test = FashionDataset(df_test, transforms=test_transforms, \\\n                           train=False)\ntestloader = DataLoader(data_test, batch_size=BATCH_SIZE, \\\n                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, \\\n                         shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_ckpt()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_out = make_preds(testloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = pd.DataFrame(data_out, columns=['ID', 'label'])\ndf_out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}